{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import pickle\n",
    "\n",
    "from skimage.transform import rescale, resize, rotate\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.metrics import confusion_matrix, auc, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras import callbacks\n",
    "from keras.models import load_model\n",
    "\n",
    "from image_handler import ImageHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "random_state = 42\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/annotated_honeybee/bee_data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "# from tensorflow.keras.preprocessing import image# Helper libraries\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as pl\n",
    "# loaded_model = keras.models.load_model(\"../varroa_det_model_v1\")\n",
    "\n",
    "# # img = image.load_img('../annotated-honeybee-dataset/bee_imgs/040_063.png', target_size=(IDEAL_WIDTH, IDEAL_HEIGHT))\n",
    "# img = image.load_img('../test_dataset/honeybee_with_varroa/001_005.jpg', target_size=(IDEAL_WIDTH, IDEAL_HEIGHT))\n",
    "# img_array = image.img_to_array(img)\n",
    "# img_batch = np.expand_dims(img_array, axis=0)\n",
    "# img_preprocessed = preprocess_input(img_batch)\n",
    "# prediction = loaded_model.predict(img_preprocessed)\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_counts = data[\"health\"].value_counts()\n",
    "health_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_categories = [name for name in health_counts.index if \"varr\" in name.lower() or \"health\" in name.lower()]\n",
    "target_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[status in target_categories for status in data[\"health\"]]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"has_varroa\"] = (data[\"health\"] != \"healthy\").astype(int)\n",
    "data[\"has_varroa\"].head() #0: healthy; 1: has_varroa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"has_varroa\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data[[\"file\",\"has_varroa\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_counts = data[\"has_varroa\"].value_counts()\n",
    "health_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Counts of bee $health$ categories\")\n",
    "g = sns.barplot(x = health_counts, y = health_counts.index, orient=\"h\");\n",
    "plt.yticks([0,1],[\"Healthy\",\"Varroa\"])\n",
    "g.set_xlabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(files):\n",
    "    IMAGE_FILE_ROOT = '../datasets/annotated_honeybee/bee_imgs/' \n",
    "    return np.asanyarray([imageio.imread(\"{}{}\".format(IMAGE_FILE_ROOT, file)) for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, ax = plt, title = None, show_size = False):\n",
    "    ax.imshow(image)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    if not show_size:\n",
    "        ax.tick_params(bottom = False, left = False, labelbottom = False, labelleft = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(files, titles = None, show_size = False):\n",
    "    cols = 4\n",
    "    f, ax = plt.subplots(nrows=int(np.ceil(len(files)/cols)),ncols=cols, figsize=(14,5))\n",
    "    ax = ax.flatten()\n",
    "    for i, file in enumerate(files):\n",
    "        if titles:\n",
    "            show_image(file, ax = ax[i], title = titles[i], show_size = show_size)\n",
    "        else:\n",
    "            show_image(file, ax = ax[i], title = None, show_size = show_size)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_images = get_image_data(data[\"file\"].values)\n",
    "show_image(raw_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_images(raw_images[::1200], list(data[\"has_varroa\"].map({1: \"has_varroa\", 0: \"healthy\"})[::1200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_wh(images):\n",
    "    '''Returns a tuple of lists, representing the widths and heights of the give images, respectively.'''\n",
    "    widths = []\n",
    "    heights = []\n",
    "    for image in images:\n",
    "        h, w, rbg = image.shape\n",
    "        widths.append(w)\n",
    "        heights.append(h)\n",
    "    return (widths, heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_average(dist, cutoff = .5):\n",
    "    '''Returns an integer of the average from the given distribution above the cutoff.'''\n",
    "    # requires single peak normal-like distribution\n",
    "    hist, bin_edges = np.histogram(dist, bins = 25);\n",
    "    total_hist = sum(hist)\n",
    "    \n",
    "    # associating proportion of hist with bin_edges\n",
    "    hist_edges = [(vals[0]/total_hist,vals[1]) for vals in zip(hist, bin_edges)]\n",
    "    \n",
    "    # sorting by proportions (assumes normal-like dist such that high freq. bins are close together)\n",
    "    hist_edges.sort(key = lambda x: x[0])\n",
    "    lefts = []\n",
    "    \n",
    "    # add highest freq. bins to list up to cutoff % of total\n",
    "    while cutoff > 0:\n",
    "        vals = hist_edges.pop()\n",
    "        cutoff -= vals[0]\n",
    "        lefts.append(vals[1])\n",
    "        \n",
    "    # determining leftmost and rightmost range, then returning average\n",
    "    diff = np.abs(np.diff(lefts)[0]) # same diff b/c of bins\n",
    "    leftmost = min(lefts)\n",
    "    rightmost = max(lefts) + diff\n",
    "    return int(np.round(np.mean([rightmost,leftmost])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = get_images_wh(raw_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 18\n",
    "plt.title(\"Widths of bee images\", fontsize = size * 4/3, pad = size/2)\n",
    "plt.ylabel(\"Frequency\", size = size)\n",
    "plt.xlabel(\"width (pixels)\", size = size)\n",
    "plt.hist(wh[0], bins = 25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDEAL_WIDTH, IDEAL_HEIGHT = get_best_average(wh[0]), get_best_average(wh[1])\n",
    "IDEAL_WIDTH, IDEAL_HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# IMAGE_FILE_ROOT = '../annotated-honeybee-dataset/bee_imgs/'\n",
    "# resized_images = []\n",
    "# # raw_images = get_image_data(data[\"file\"].values)\n",
    "# for filename in data[\"file\"].values:\n",
    "#     img = cv2.imread(IMAGE_FILE_ROOT + filename, cv2.IMREAD_COLOR)\n",
    "#     img = cv2.resize(img, (IDEAL_WIDTH, IDEAL_HEIGHT))\n",
    "#     resized_images.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizing = (IDEAL_WIDTH, IDEAL_HEIGHT, 3)\n",
    "\n",
    "sample_img_store = ImageHandler(raw_images[:201]).resize(resizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_image_1 = raw_images[100]\n",
    "new_image_1 = sample_img_store.images_for_display[100]\n",
    "\n",
    "old_image_2 = raw_images[200]\n",
    "new_image_2 = sample_img_store.images_for_display[200]\n",
    "show_images(\n",
    "    [old_image_1, new_image_1, old_image_2, new_image_2], \n",
    "    titles = [\"Original #1 (tall)\", \"Resized #1\", \"Original #2 (wide)\", \"Resized #2\"], \n",
    "    show_size = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 3\n",
    "dropout = .5\n",
    "batch_size = 54\n",
    "activation_func = \"relu\"\n",
    "input_shape = (batch_size, 50, 3)\n",
    "\n",
    "conv__filters_1 = 32\n",
    "conv__filters_2 = 48\n",
    "conv__filters_3 = 64\n",
    "density_units_1 = 256\n",
    "density_units_2 = 64\n",
    "epochs          = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    '''\n",
    "    Returns the given np.array image rescaled and normalized to be between -.5 and .5\n",
    "    \n",
    "    Source: https://www.jeremyjordan.me/batch-normalization/\n",
    "    '''\n",
    "    return (image/255. - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datagens(\n",
    "    data, datagen_params, \n",
    "    target_shape, batch_size, x_col=\"file\", y_col=\"has_varroa\", IMAGE_FILE_ROOT = '../datasets/annotated_honeybee/bee_imgs/', \n",
    "    random_state = None, preprocessing_function = None):\n",
    "        '''\n",
    "        Appropriately creates and returns two ImageDataGenerator objects - one for training and one for testing.\n",
    "        \n",
    "        ImageDataGenerator objects are responsible for handling image data during model training, by pulling the data\n",
    "        directly from the image data directory, resizing the image, and applying the appropriate transformations.\n",
    "        \n",
    "        The testing ImageDataGenerator object does not apply any transformations.\n",
    "        '''\n",
    "        data[y_col] = data[y_col].astype(str) # coercion needed for datagen\n",
    "        # train/test split\n",
    "        train, test = train_test_split(\n",
    "            data, \n",
    "            test_size = 2/3, \n",
    "            stratify = data.iloc[:,-1], # assumed last column is target variable\n",
    "            random_state = random_state\n",
    "            )\n",
    "        \n",
    "        # training ImageDataGenerator\n",
    "        datagen = ImageDataGenerator(\n",
    "            horizontal_flip  = datagen_params.get(\"horizontal_flip\") or False, \n",
    "            vertical_flip    = datagen_params.get(\"vertical_flip\") or False, \n",
    "            rotation_range   = datagen_params.get(\"rotation_range\") or False,\n",
    "            brightness_range = datagen_params.get(\"brightness_range\"),\n",
    "            preprocessing_function = preprocessing_function\n",
    "        )\n",
    "\n",
    "        datagen_iter_train = datagen.flow_from_dataframe(\n",
    "            train, \n",
    "            directory   = IMAGE_FILE_ROOT, \n",
    "            x_col       = x_col,\n",
    "            y_col       = y_col,\n",
    "            target_size = target_shape, \n",
    "            color_mode  = 'rgb', \n",
    "            class_mode  = 'binary', \n",
    "            batch_size  = batch_size, \n",
    "            shuffle     = True,\n",
    "            seed        = random_state\n",
    "        )\n",
    "\n",
    "        # testing ImageDataGenerator\n",
    "        datagen_test = ImageDataGenerator(preprocessing_function = preprocessing_function)\n",
    "\n",
    "        datagen_iter_test = datagen_test.flow_from_dataframe(\n",
    "            test, \n",
    "            directory   = IMAGE_FILE_ROOT, \n",
    "            x_col       = x_col,\n",
    "            y_col       = y_col,\n",
    "            target_size = target_shape, \n",
    "            color_mode  = 'rgb', \n",
    "            class_mode  = 'binary', \n",
    "            batch_size  = 1, \n",
    "            shuffle     = False\n",
    "        )\n",
    "        \n",
    "        return datagen_iter_train, datagen_iter_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutate_params(grid_params):\n",
    "    '''Returns a list of all combinations of unique parameters from the given dictionary'''\n",
    "    out = [{}]\n",
    "    \n",
    "    # loop through each key/val pair\n",
    "    for param_name, param_list in grid_params.items():\n",
    "        # shortcircut - no need to permute single items\n",
    "        if len(param_list) == 1:\n",
    "            for item in out:\n",
    "                item[param_name] = param_list[0]\n",
    "        else:\n",
    "            temp_out = []\n",
    "            # for each item in the param, clone entire growing list and add param to each\n",
    "            for param_val in param_list:\n",
    "                for item in out:\n",
    "                    cloned_item = item.copy()\n",
    "                    cloned_item[param_name] = param_val\n",
    "                    temp_out.append(cloned_item)\n",
    "            out = temp_out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_from_datagen(\n",
    "    params = dict(), \n",
    "    input_shape = (), \n",
    "    datagen_iter_train = None, \n",
    "    datagen_iter_val = None, \n",
    "    optimizer = \"adam\",\n",
    "    file_name = None\n",
    "):\n",
    "    '''Returns a fitted convolutional neural network with the given parameters and data.'''\n",
    "    kernel_size = 3\n",
    "    dropout = .5\n",
    "    activation_func = \"relu\"\n",
    "\n",
    "    conv__filters_1 = params.get('conv__filters_1') or 32\n",
    "    conv__filters_2 = params.get('conv__filters_2') or 16\n",
    "    conv__filters_3 = params.get('conv__filters_3') or 32\n",
    "    density_units_1 = params.get('density_units_1') or 32\n",
    "    density_units_2 = params.get('density_units_2') or 32\n",
    "    epochs          = params.get('epochs') or 8\n",
    "    \n",
    "    # instantiating model\n",
    "    model = Sequential([\n",
    "        # Conv layer #1\n",
    "        Conv2D(\n",
    "            filters = conv__filters_1, \n",
    "            kernel_size = kernel_size + 4, \n",
    "            activation  = activation_func, \n",
    "            input_shape = input_shape, #input layer\n",
    "            padding     = \"same\"\n",
    "        ),\n",
    "        Conv2D(filters = conv__filters_1, kernel_size = kernel_size + 4, activation = activation_func, padding = \"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(dropout/2),\n",
    "\n",
    "        # Conv layer #2\n",
    "        Conv2D(filters = conv__filters_2, kernel_size = kernel_size + 2, activation=activation_func, padding = \"same\"),\n",
    "        Conv2D(filters = conv__filters_2, kernel_size = kernel_size + 2, activation = activation_func, padding = \"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(dropout/2),\n",
    "\n",
    "        # Conv layer #3\n",
    "        Conv2D(filters = conv__filters_3, kernel_size = kernel_size, activation=activation_func, padding = \"same\"),\n",
    "        Conv2D(filters = conv__filters_3, kernel_size = kernel_size, activation = activation_func, padding = \"same\"),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(dropout/2),\n",
    "\n",
    "        # Dense layer #1\n",
    "        Flatten(),\n",
    "        Dense(density_units_1, activation=activation_func),\n",
    "        Dropout(dropout),\n",
    "        \n",
    "        # Dense layer #2\n",
    "        Dense(density_units_2, activation=activation_func),\n",
    "        Dropout(dropout),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # compiling model\n",
    "    model.compile(\n",
    "        loss      = 'binary_crossentropy',\n",
    "        optimizer = optimizer,\n",
    "        metrics   = ['binary_accuracy']\n",
    "    )\n",
    "    \n",
    "    # fitting model w/ImageDataGenerator\n",
    "    STEP_SIZE_TRAIN= np.ceil(datagen_iter_train.n/datagen_iter_train.batch_size)\n",
    "    STEP_SIZE_VALID= np.ceil(datagen_iter_val.n/datagen_iter_val.batch_size)\n",
    "\n",
    "    # NOTE: the best model is saved to disk via callbacks, and is a retrievable file\n",
    "    history = model.fit_generator(\n",
    "        generator           = datagen_iter_train,\n",
    "        steps_per_epoch     = STEP_SIZE_TRAIN,\n",
    "        validation_data     = datagen_iter_val,\n",
    "        validation_steps    = STEP_SIZE_VALID,\n",
    "        epochs              = epochs,\n",
    "        callbacks           = [callbacks.ModelCheckpoint(file_name, save_best_only=True, mode='auto', period=1)]\n",
    "    )\n",
    "    \n",
    "    return (model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearchCNN(\n",
    "    datagens,\n",
    "    grid_params, \n",
    "    file_name,\n",
    "    optimizer = \"adam\",\n",
    "    random_state = None,\n",
    "):\n",
    "    '''\n",
    "    Iteratively discovers and then returns an optimized convolutional neural network with the given grid_params\n",
    "    \n",
    "    Much of the code related to datagen came from:\n",
    "    https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
    "    '''\n",
    "    # list of all parameter combinations\n",
    "    all_params = permutate_params(grid_params) \n",
    "    \n",
    "    # establishing variables\n",
    "    best_model   = None\n",
    "    best_score   = 0.0 # no accuracy to start\n",
    "    best_params  = None\n",
    "    best_history = None\n",
    "    test_scores  = None\n",
    "    train_scores = None\n",
    "    \n",
    "    datagen_iter_train, datagen_iter_test = datagens\n",
    "    \n",
    "    # for each permuted parameter, try fitting a model (NOTE: the best model is saved to disk with file_name)\n",
    "    for params in all_params:\n",
    "        model, history = build_model_from_datagen(\n",
    "            params, \n",
    "            input_shape        = datagen_iter_train.image_shape,\n",
    "            datagen_iter_train = datagen_iter_train,\n",
    "            datagen_iter_val   = datagen_iter_test,\n",
    "            optimizer          = optimizer,\n",
    "            file_name          = file_name\n",
    "        )\n",
    "\n",
    "        acc = max(history.history[\"val_binary_accuracy\"])\n",
    "        \n",
    "        # only keeping best\n",
    "        if acc > best_score:\n",
    "            print(\"***Good Accurary found: {:.2%}***\".format(acc))\n",
    "            best_score   = acc\n",
    "            test_scores  = history.history[\"val_binary_accuracy\"]\n",
    "            train_scores = history.history[\"binary_accuracy\"]\n",
    "            best_model   = model\n",
    "            best_params  = params\n",
    "            best_history = history\n",
    "    \n",
    "    # returns metadata of results (NOTE: retrieving best model from hard disk)\n",
    "    return {\n",
    "        \"best_model\"   : load_model(file_name),\n",
    "        \"best_score\"   : best_score,\n",
    "        \"best_params\"  : best_params,\n",
    "        \"best_history\" : best_history,\n",
    "        \"test_scores\"  : test_scores,\n",
    "        \"train_scores\" : train_scores\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix_stats(y_test, preds):\n",
    "    ''' Return key confusion matrix metrics given true and predicted values'''\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    TP, FP, FN, TN, = cm[1,1], cm[0,1], cm[1,0], cm[0,0]\n",
    "    total = (TP + FP + FN + TN)\n",
    "    acc = (TP + TN ) / total\n",
    "    miss = 1 - acc\n",
    "    sens = TP / (TP + FN)\n",
    "    spec = TN / (TN + FP)\n",
    "    prec = TP / (TP + FP)\n",
    "    return {\"accuracy\": acc, \"miss_rate\": miss, \"sensitivity\": sens, \"specification\": spec, \"precision\": prec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_loss(history):\n",
    "    '''\n",
    "    Graphs the training and testing loss using the given History object from model training\n",
    "    \n",
    "    Note: this function was modified from code provided by Riley Dallas (General Assembly instructor - 11.04-lesson-cnn)\n",
    "    '''\n",
    "    # Check out our train loss and test loss over epochs.\n",
    "    train_loss = history.history['loss']\n",
    "    test_loss = history.history['val_loss']\n",
    "    xticks = np.array(range(len(train_loss)))\n",
    "    # Set figure size.\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Generate line plot of training, testing loss over epochs.\n",
    "    plt.plot(train_loss, label='Training Loss', color='#185fad')\n",
    "    plt.plot(test_loss, label='Testing Loss', color='orange')\n",
    "\n",
    "    # Set title\n",
    "    plt.title('Training and Testing Loss by Epoch', fontsize = 25)\n",
    "    plt.xlabel('Epoch', fontsize = 18)\n",
    "    plt.ylabel('Binary Crossentropy', fontsize = 18)\n",
    "    plt.xticks(xticks[::5], (xticks+1)[::5])\n",
    "\n",
    "    plt.legend(fontsize = 18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(images, shapes, title, ncols = 4, height = 2, width = 2):\n",
    "    '''Plots list of given images'''\n",
    "    nrows = int(np.ceil(len(images)/ncols))\n",
    "    f, ax = plt.subplots(nrows=nrows,ncols=ncols, figsize=(ncols * width, nrows * height))\n",
    "    ax = ax.flatten() if type(ax) == np.ndarray else ax\n",
    "    i = None\n",
    "    for i, image in enumerate(images):\n",
    "        _title = f\"Orig. size: {shapes[i][0]}x{shapes[i][1]}\\n{title} #{i+1}\"\n",
    "        show_image(image, ax = ax[i] if type(ax) == np.ndarray else ax, title = _title)\n",
    "    \n",
    "    # removing extraneous subplots\n",
    "    while i and type(ax) == np.ndarray and i < len(ax) - 1:\n",
    "        i += 1\n",
    "        f.delaxes(ax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"../models/\"\n",
    "model_name = \"varroa_detection_v100\"\n",
    "stored_model_path = f\"{MODEL_PATH}/{model_name}.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 1478 invalid image filename(s) in x_col=\"file\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 2957 invalid image filename(s) in x_col=\"file\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
>>>>>>> main
   "source": [
    "datagen_params = {\n",
    "    \"horizontal_flip\"  : True,    \n",
    "    \"vertical_flip\"    : True,\n",
    "    \"rotation_range\"   : 360,\n",
    "    \"brightness_range\" : [.7, 1.]\n",
    "}\n",
    "\n",
    "datagens = create_datagens(\n",
    "    data, \n",
    "    datagen_params         = datagen_params,\n",
    "    batch_size             = 64, # hyperparameter\n",
    "    target_shape           = (IDEAL_WIDTH, IDEAL_HEIGHT), \n",
    "    preprocessing_function = normalize,\n",
    "    random_state           = random_state\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    \"conv__filters_1\" : [32],\n",
    "    \"conv__filters_2\" : [48],\n",
    "    \"conv__filters_3\" : [64],\n",
    "    \"density_units_1\" : [256],\n",
    "    \"density_units_2\" : [64],\n",
    "    \"batch_size\"      : [64],\n",
    "    \"epochs\"          : [50]\n",
    "}\n",
    "\n",
    "best_bright_model = gridSearchCNN(\n",
    "    datagens     = datagens,\n",
    "    grid_params  = grid_params, \n",
    "    random_state = random_state,\n",
    "    optimizer    = RMSprop(lr = 0.0001, decay = 1e-6),\n",
    "    file_name    = f\"{MODEL_PATH}/best_{model_name}.h5\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_bright_model[\"best_model\"].save(\"../models/varroa_det_model_v100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# loaded_model = keras.models.load_model(\"../models/varroa_det_model_v100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TensorFlow and tf.kerasimport tensorflow as tf\n",
    "# from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "# from tensorflow.keras.preprocessing import image# Helper libraries\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as pl\n",
    "# # img = image.load_img('../annotated-honeybee-dataset/bee_imgs/005_537.png', target_size=(IDEAL_WIDTH, IDEAL_HEIGHT))\n",
    "# img = image.load_img('../test_dataset/honeybee_with_varroa/001_001.jpeg', target_size=(IDEAL_WIDTH, IDEAL_HEIGHT))\n",
    "# img_array = image.img_to_array(img)\n",
    "# img_batch = np.expand_dims(img_array, axis=0)\n",
    "# img_preprocessed = preprocess_input(img_batch)\n",
    "# prediction = loaded_model.predict(img_preprocessed)\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = image.load_img('../test_dataset/honeybee_with_varroa/001_005.jpg', target_size=(IDEAL_WIDTH, IDEAL_HEIGHT))\n",
    "# img_array = image.img_to_array(img)\n",
    "# img_batch = np.expand_dims(img_array, axis=0)\n",
    "# img_preprocessed = preprocess_input(img_batch)\n",
    "# prediction = loaded_model.predict(img_preprocessed)\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = best_bright_model[\"best_model\"]\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen_iter_test = datagens[1]\n",
    "datagen_iter_test.reset()_preds = my_model.predict_generator(datagen_iter_test, steps = datagen_iter_test.n)\n",
    "preds = (_preds >= .5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives_files = bright_missed[(bright_missed[\"has_varroa\"] != bright_missed[\"pred\"]) & (bright_missed[\"pred\"] == 1)][\"file\"]\n",
    "_images = get_image_data(false_positives_files)\n",
    "show_results(_images, [image.shape for image in _images], \"false pos.\", ncols=1, width = 5, height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_preds = pd.DataFrame({\n",
    "    \"file\"       : datagen_iter_test.filenames,\n",
    "    \"has_varroa\" : datagen_iter_test.classes,\n",
    "    \"pred\"       : preds\n",
    "})\n",
    "\n",
    "(bright_preds[\"has_varroa\"] == bright_preds[\"pred\"]).value_counts(normalize=True)\n",
    "bright_missed = bright_preds[bright_preds[\"has_varroa\"] != bright_preds[\"pred\"]]\n",
    "bright_missed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative_files = bright_missed[(bright_missed[\"has_varroa\"] != bright_missed[\"pred\"]) & (bright_missed[\"pred\"] == 0)][\"file\"]\n",
    "_images = get_image_data(false_negative_files)\n",
    "show_results(_images, [image.shape for image in _images], \"false neg.\", ncols=3, height = 4, width = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = best_bright_model[\"best_model\"]\n",
    "len(classifier.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the outputs of the top 18 layers\n",
    "layer_outputs = [layer.output for layer in classifier.layers[:18]] \n",
    "activation_model = models.Model(inputs=classifier.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resizing = (IDEAL_WIDTH, IDEAL_HEIGHT, 3)\n",
    "\n",
    "sample_img_store = ImageHandler(raw_images[:201]).resize(resizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(sample_img_store.images_for_display[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(sample_img_store.images_for_display[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.predict(sample_img_store.images_for_display[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.predict(sample_img_store.images_for_display[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample_img_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export model\n",
    "# model_path = \"../varroa_detection_v0\"\n",
    "# best_bright_model.save(model_path)\n",
    "\n",
    "pickle.dump(best_bright_model[\"best_model\"], open(stored_model_path, 'wb')) # saving metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bright_model = pickle.load(open(stored_model_path, 'rb')) # loading metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
